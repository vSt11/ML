{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercice 4 : impact et detection d'outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation de donnees test\n",
    "def generate_data(n_samples, outlier=False, b_1=4.):\n",
    "    x = np.arange(n_samples)\n",
    "    y = 10. + b_1*x + np.random.randn(n_samples)*3.\n",
    "    if outlier:\n",
    "        y[-1] += 20\n",
    "    return x, y\n",
    "\n",
    "def s2(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    SSE = np.sum((y_true - y_pred)**2)\n",
    "    return SSE / (n-1)\n",
    "\n",
    "\n",
    "x, y = generate_data(n_samples=10, outlier=True)\n",
    "# instanciation de sklearn.linear_model.LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x[:, np.newaxis], y)  # np.newaxis est utilise car x doit etre une matrice 2d avec 'LinearRegression'\n",
    "\n",
    "# representation du resultat\n",
    "\n",
    "print('b_0='+str(lr.intercept_)+' et b_1='+str(lr.coef_[0]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.plot(x, lr.predict(x[:, np.newaxis]), 'b-')\n",
    "plt.legend(('Data', 'Linear Fit'), loc='lower right')\n",
    "plt.title('Linear regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTION 4.1 :</span> \n",
    "\n",
    "\n",
    "Remarquons que la ligne 'y[9]=y[9]+20' génere artificiellement une donnée aberrante.\n",
    "\n",
    "Tester l'impact de la donnée aberrante en estimant b_0, b_1 et s^2 sur \n",
    "- 5 jeux de données générés comme dans la cellule précédente et\n",
    "- 5 autres jeux aussi générés suivant cette méthode, mais sans la données aberrant (simplement ne pas executer la ligne y[9]=y[9]+20).\n",
    "\n",
    "On remarque que $\\beta_0 = 10$, $\\beta_1 = 4$ et $\\sigma=3$ dans les données simulees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 4.1 :</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variance estimée du bruit est beaucoup plus grande avec une donnée aberrante.\n",
    "La donnée aberrante introiduit un biais dans l'estimation des statistiques b_0 et b_1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTIONS 4.2 :</span> \n",
    "\n",
    "#### <span style=\"color:blue\">QUESTION 4.2.a :</span> \n",
    "Pour chaque variable i, calculez les profils des résidus $e_{(i)j}=y_j - \\hat{y_{(i)j}}$ pour tous les j, où  \\hat{y_{(i)j}} est l'estimation de y_j à partir d'un modele  linéaire appris sans l'observation i.\n",
    "#### <span style=\"color:blue\">QUESTION 4.2.b :</span> \n",
    "En quoi le profil des e_{(i)j} est différent pour i=9 que pour les autres i\n",
    "#### <span style=\"color:blue\">QUESTION 4.2.c :</span> \n",
    "Etendre ces calculs pour définir la distance de Cook de chaque variable i\n",
    "\n",
    "AIDE : pour enlever un élement 'i' de 'x' ou 'y', utiliser x_del_i=np.delete(x,i) et y_del_i=np.delete(y,i) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_data(n_samples=10, outlier=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 4.2.a :</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profil_residuel(x, y, i):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 4.2.b :</span> \n",
    "\n",
    "Le profil résiduel de la donnée aberrante est toujours plus grand que les autres, en particulier lorsqu'on ôte la donnée de la base d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook(x, y, i):\n",
    "    ...\n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 4.2.c :</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un jeu de données de 20 observations obtenues avec un coefficient directeur $\\beta_1$ de $0.2$, faire un test d'hypothèse pour vérifier que les données sont corrélées avec une confiance de 95%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que sous les hypothèses suivantes : \n",
    " * $\\mathbb{E}[\\epsilon_i] = 0$,\n",
    " * $\\mathbb{V}[\\epsilon_i] = \\sigma^2$,\n",
    " * $\\forall i \\neq j, \\: Cov(\\epsilon_i, \\epsilon_j) = 0$,\n",
    " \n",
    "on a : \n",
    "\n",
    "* $\\mathbb{E}[\\hat{\\beta_0}] = \\beta_0$,\n",
    "* $\\mathbb{E}[\\hat{\\beta_1}] = \\beta_1$,\n",
    "* $\\mathbb{V}[\\hat{\\beta_0}] = \\sigma^2(\\frac{1}{n} + \\frac{\\bar{x_n}^2}{\\sum_{i=1}^n (x_i - \\bar{x_n})^2})$,\n",
    "* $\\mathbb{V}[\\hat{\\beta_1}] = \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x_n})^2}$\n",
    "\n",
    "En faisant l'hypothèse supplémentaire que les erreurs suivent une loi normale, $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$, on a :\n",
    "\n",
    "* $\\hat{\\beta_1} \\sim \\mathcal{N}(\\beta_1, \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x_n})^2})$,\n",
    "* $\\frac{(n-2) \\cdot s^2}{\\sigma^2} \\sim \\mathcal{X}^2(n-2)$,\n",
    "* $\\hat{\\beta_1}$ et $s^2$ indépendants,\n",
    "\n",
    "où $s^2 = \\frac{\\sum_{i=1}^n \\hat{\\epsilon_i}^2}{n-2}$ est un estimateur non biaisé de $\\sigma^2$.\n",
    "\n",
    "On peut en déduire que:\n",
    "\n",
    "$$ \\frac{ \\frac{ \\hat{\\beta_1}-\\beta_1}{\\sqrt{\\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x_n})^2}}}}{\\sqrt{\\frac{\\frac{(n-2)s^2}{\\sigma^2}}{n-2}}} = \\frac{\\hat{\\beta_1}-\\beta_1}{\\frac{s}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x_n})^2}}} = T_n \\sim T(n-2)$$ \n",
    "\n",
    "où $T(n-2)$ désigne la loi de Student à $n-2$ degrés de liberté, d'espérance nulle si $n-2 > 1$.\n",
    "\n",
    "Tester l'hypothèse H_0 : $\\beta_1 = 0$ en prenant un risque de 5%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
